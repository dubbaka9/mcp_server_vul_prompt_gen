{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ffe93-0ee8-4824-b477-81ebf1b36e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Prompt Generator using LangChain\n",
    "Generates more accurate prompts for vulnerability fixes\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate, \n",
    "    ChatPromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class VulnerabilityFix(BaseModel):\n",
    "    \"\"\"Structure for vulnerability fix output\"\"\"\n",
    "    fixed_code: str = Field(description=\"The secure fixed code\")\n",
    "    explanation: str = Field(description=\"Explanation of the fix\")\n",
    "    security_considerations: List[str] = Field(description=\"Security considerations\")\n",
    "    testing_notes: str = Field(description=\"How to test the fix\")\n",
    "\n",
    "\n",
    "class LangChainFortifyPromptGenerator:\n",
    "    \"\"\"Enhanced prompt generator using LangChain\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = \"prompts\"):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Initialize embeddings for semantic similarity\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        \n",
    "        # Initialize prompt templates\n",
    "        self.system_template = self._create_system_template()\n",
    "        self.few_shot_examples = self._load_few_shot_examples()\n",
    "        self.example_selector = self._create_example_selector()\n",
    "        \n",
    "    def _create_system_template(self) -> str:\n",
    "        \"\"\"Create the system prompt template\"\"\"\n",
    "        return \"\"\"You are an expert security engineer specializing in fixing vulnerabilities.\n",
    "        \n",
    "Your expertise includes:\n",
    "- Deep understanding of {vulnerability_type} vulnerabilities\n",
    "- {language} programming language security best practices\n",
    "- OWASP security guidelines\n",
    "- Secure coding patterns\n",
    "\n",
    "You always:\n",
    "1. Provide minimal, focused fixes that address the specific vulnerability\n",
    "2. Maintain existing functionality\n",
    "3. Follow the principle of least privilege\n",
    "4. Add appropriate input validation and output encoding\n",
    "5. Use the most secure methods available in {language}\n",
    "6. Consider the full context and data flow\"\"\"\n",
    "\n",
    "    def _load_few_shot_examples(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Load few-shot examples for different vulnerability types\"\"\"\n",
    "        return [\n",
    "            # SQL Injection Example\n",
    "            {\n",
    "                \"vulnerability_type\": \"SQL Injection\",\n",
    "                \"vulnerable_code\": \"\"\"\n",
    "const userId = req.params.userId;\n",
    "const query = `SELECT * FROM users WHERE id = '${userId}'`;\n",
    "db.query(query, callback);\n",
    "\"\"\",\n",
    "                \"fixed_code\": \"\"\"\n",
    "const userId = req.params.userId;\n",
    "const query = 'SELECT * FROM users WHERE id = ?';\n",
    "db.query(query, [userId], callback);\n",
    "\"\"\",\n",
    "                \"explanation\": \"Used parameterized queries to prevent SQL injection\"\n",
    "            },\n",
    "            # XSS Example\n",
    "            {\n",
    "                \"vulnerability_type\": \"Cross-Site Scripting: DOM\",\n",
    "                \"vulnerable_code\": \"\"\"\n",
    "const userInput = getUrlParameter('redirect');\n",
    "window.location.href = userInput;\n",
    "\"\"\",\n",
    "                \"fixed_code\": \"\"\"\n",
    "const userInput = getUrlParameter('redirect');\n",
    "const allowedDomains = ['example.com', 'app.example.com'];\n",
    "const url = new URL(userInput, window.location.origin);\n",
    "\n",
    "if (allowedDomains.includes(url.hostname)) {\n",
    "    window.location.href = url.toString();\n",
    "} else {\n",
    "    console.error('Invalid redirect URL');\n",
    "    window.location.href = '/';\n",
    "}\n",
    "\"\"\",\n",
    "                \"explanation\": \"Added URL validation with allowlist to prevent open redirect\"\n",
    "            },\n",
    "            # Path Traversal Example\n",
    "            {\n",
    "                \"vulnerability_type\": \"Path Traversal\",\n",
    "                \"vulnerable_code\": \"\"\"\n",
    "const filename = req.query.file;\n",
    "const filepath = './uploads/' + filename;\n",
    "fs.readFile(filepath, callback);\n",
    "\"\"\",\n",
    "                \"fixed_code\": \"\"\"\n",
    "const path = require('path');\n",
    "const filename = req.query.file;\n",
    "const safeFilename = path.basename(filename);\n",
    "const filepath = path.join(__dirname, 'uploads', safeFilename);\n",
    "\n",
    "// Ensure the resolved path is within the uploads directory\n",
    "const uploadsDir = path.resolve(__dirname, 'uploads');\n",
    "const resolvedPath = path.resolve(filepath);\n",
    "\n",
    "if (resolvedPath.startsWith(uploadsDir)) {\n",
    "    fs.readFile(resolvedPath, callback);\n",
    "} else {\n",
    "    callback(new Error('Invalid file path'));\n",
    "}\n",
    "\"\"\",\n",
    "                \"explanation\": \"Used path.basename() and validated resolved path stays within allowed directory\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def _create_example_selector(self) -> SemanticSimilarityExampleSelector:\n",
    "        \"\"\"Create semantic similarity selector for examples\"\"\"\n",
    "        if not self.few_shot_examples:\n",
    "            return None\n",
    "            \n",
    "        # Format examples for the selector\n",
    "        examples = []\n",
    "        for ex in self.few_shot_examples:\n",
    "            examples.append({\n",
    "                \"input\": f\"Fix {ex['vulnerability_type']} in: {ex['vulnerable_code']}\",\n",
    "                \"output\": f\"Fixed code: {ex['fixed_code']}\\nExplanation: {ex['explanation']}\"\n",
    "            })\n",
    "        \n",
    "        # Create vector store\n",
    "        example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "            examples,\n",
    "            self.embeddings,\n",
    "            FAISS,\n",
    "            k=2  # Select top 2 most relevant examples\n",
    "        )\n",
    "        \n",
    "        return example_selector\n",
    "    \n",
    "    def create_enhanced_prompt(self, vulnerability_data: Dict, code_context: str) -> ChatPromptTemplate:\n",
    "        \"\"\"Create an enhanced prompt using LangChain templates\"\"\"\n",
    "        \n",
    "        # Create few-shot prompt if we have examples\n",
    "        if self.example_selector:\n",
    "            few_shot_prompt = FewShotPromptTemplate(\n",
    "                example_selector=self.example_selector,\n",
    "                example_prompt=PromptTemplate(\n",
    "                    input_variables=[\"input\", \"output\"],\n",
    "                    template=\"Example:\\nInput: {input}\\n{output}\\n\"\n",
    "                ),\n",
    "                prefix=\"Here are some examples of similar vulnerability fixes:\\n\",\n",
    "                suffix=\"Now fix this vulnerability:\\n\",\n",
    "                input_variables=[\"vulnerability_info\"]\n",
    "            )\n",
    "        \n",
    "        # Create the main chat prompt\n",
    "        messages = [\n",
    "            SystemMessagePromptTemplate.from_template(self.system_template),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                self._create_human_template()\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    def _create_human_template(self) -> str:\n",
    "        \"\"\"Create the human message template\"\"\"\n",
    "        return \"\"\"Fix this {vulnerability_type} vulnerability:\n",
    "\n",
    "## Vulnerability Details\n",
    "- Issue ID: {issue_id}\n",
    "- File: {file_path}\n",
    "- Line: {line_number}\n",
    "- Severity: {severity}\n",
    "- Scanner: {scanner}\n",
    "\n",
    "## Fortify Analysis\n",
    "{recommendation}\n",
    "\n",
    "## Analysis Trace\n",
    "{analysis_trace}\n",
    "\n",
    "## Current Vulnerable Code (Line {line_number})\n",
    "```{language}\n",
    "{code_context}\n",
    "```\n",
    "\n",
    "## Additional Context\n",
    "- Framework: {framework}\n",
    "- Dependencies: {dependencies}\n",
    "- Security Headers: {security_headers}\n",
    "\n",
    "## Requirements\n",
    "1. Fix the vulnerability at line {line_number}\n",
    "2. Use {language} best practices\n",
    "3. Maintain backward compatibility\n",
    "4. Add appropriate error handling\n",
    "5. Include input validation where needed\n",
    "\n",
    "Provide:\n",
    "1. The complete fixed code\n",
    "2. Explanation of the fix\n",
    "3. Security considerations\n",
    "4. Testing recommendations\"\"\"\n",
    "\n",
    "    def generate_prompt_with_context_enhancement(self, vulnerability: Dict, code_context: str) -> str:\n",
    "        \"\"\"Generate enhanced prompt with additional context\"\"\"\n",
    "        \n",
    "        # Normalize vulnerability data\n",
    "        vuln_data = self._normalize_vulnerability_data(vulnerability)\n",
    "        \n",
    "        # Enhance with additional context\n",
    "        enhanced_data = self._enhance_vulnerability_context(vuln_data, code_context)\n",
    "        \n",
    "        # Create the prompt template\n",
    "        prompt_template = self.create_enhanced_prompt(enhanced_data, code_context)\n",
    "        \n",
    "        # Format the prompt with data\n",
    "        prompt = prompt_template.format(**enhanced_data)\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _normalize_vulnerability_data(self, vulnerability: Dict) -> Dict:\n",
    "        \"\"\"Normalize and enrich vulnerability data\"\"\"\n",
    "        # Handle field name variations\n",
    "        issue_id = vulnerability.get('issueId') or vulnerability.get('issueld')\n",
    "        line_number = vulnerability.get('lineNumber') or vulnerability.get('LineNumber')\n",
    "        \n",
    "        normalized = {\n",
    "            'issue_id': issue_id,\n",
    "            'vulnerability_type': vulnerability.get('issueName', 'Unknown'),\n",
    "            'file_path': vulnerability.get('filePath', 'N/A'),\n",
    "            'line_number': line_number,\n",
    "            'severity': vulnerability.get('priority', 'Unknown'),\n",
    "            'recommendation': vulnerability.get('recommendation', 'No recommendation'),\n",
    "            'analysis_trace': self._format_analysis_trace(vulnerability.get('analysisTrace', [])),\n",
    "            'scanner': 'Fortify',\n",
    "            'language': self._detect_language(vulnerability.get('filePath', '')),\n",
    "            'status': vulnerability.get('status', 'Unknown')\n",
    "        }\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    def _enhance_vulnerability_context(self, vuln_data: Dict, code_context: str) -> Dict:\n",
    "        \"\"\"Enhance vulnerability data with additional context\"\"\"\n",
    "        enhanced = vuln_data.copy()\n",
    "        \n",
    "        # Detect framework\n",
    "        enhanced['framework'] = self._detect_framework(code_context, vuln_data['file_path'])\n",
    "        \n",
    "        # Extract dependencies\n",
    "        enhanced['dependencies'] = self._extract_dependencies(code_context)\n",
    "        \n",
    "        # Check for security headers/configurations\n",
    "        enhanced['security_headers'] = self._analyze_security_context(code_context)\n",
    "        \n",
    "        # Add code metrics\n",
    "        enhanced['code_complexity'] = self._calculate_complexity(code_context)\n",
    "        \n",
    "        # Add fix suggestions based on vulnerability type\n",
    "        enhanced['suggested_libraries'] = self._get_suggested_libraries(\n",
    "            vuln_data['vulnerability_type'], \n",
    "            vuln_data['language']\n",
    "        )\n",
    "        \n",
    "        enhanced['code_context'] = code_context\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def _detect_framework(self, code_context: str, file_path: str) -> str:\n",
    "        \"\"\"Detect the framework being used\"\"\"\n",
    "        frameworks = {\n",
    "            'express': ['express', 'app.get', 'app.post', 'req.body', 'res.json'],\n",
    "            'react': ['useState', 'useEffect', 'Component', 'render()', 'jsx'],\n",
    "            'angular': ['@Component', '@Injectable', 'ngOnInit'],\n",
    "            'vue': ['v-model', 'v-if', 'mounted()', 'data()'],\n",
    "            'django': ['django', 'models.Model', 'views.py', 'urls.py'],\n",
    "            'spring': ['@RestController', '@Service', '@Autowired'],\n",
    "            'flask': ['flask', 'Blueprint', '@app.route']\n",
    "        }\n",
    "        \n",
    "        for framework, indicators in frameworks.items():\n",
    "            if any(indicator in code_context or indicator in file_path for indicator in indicators):\n",
    "                return framework\n",
    "                \n",
    "        return 'unknown'\n",
    "    \n",
    "    def _extract_dependencies(self, code_context: str) -> List[str]:\n",
    "        \"\"\"Extract dependencies from code\"\"\"\n",
    "        dependencies = []\n",
    "        \n",
    "        # JavaScript/TypeScript imports\n",
    "        import_patterns = [\n",
    "            r\"import .* from ['\\\"]([^'\\\"]+)['\\\"]\",\n",
    "            r\"require\\(['\\\"]([^'\\\"]+)['\\\"]\\)\",\n",
    "            r\"from ([^\\s]+) import\"\n",
    "        ]\n",
    "        \n",
    "        import re\n",
    "        for pattern in import_patterns:\n",
    "            matches = re.findall(pattern, code_context)\n",
    "            dependencies.extend(matches)\n",
    "        \n",
    "        return list(set(dependencies))\n",
    "    \n",
    "    def _analyze_security_context(self, code_context: str) -> Dict[str, bool]:\n",
    "        \"\"\"Analyze security-related context\"\"\"\n",
    "        security_checks = {\n",
    "            'has_input_validation': any(x in code_context for x in ['validate', 'sanitize', 'escape']),\n",
    "            'has_authentication': any(x in code_context for x in ['auth', 'token', 'session']),\n",
    "            'has_authorization': any(x in code_context for x in ['authorize', 'permission', 'role']),\n",
    "            'has_encryption': any(x in code_context for x in ['encrypt', 'hash', 'crypto']),\n",
    "            'has_error_handling': any(x in code_context for x in ['try', 'catch', 'error'])\n",
    "        }\n",
    "        \n",
    "        return security_checks\n",
    "    \n",
    "    def _calculate_complexity(self, code_context: str) -> str:\n",
    "        \"\"\"Calculate code complexity indicator\"\"\"\n",
    "        lines = code_context.strip().split('\\n')\n",
    "        \n",
    "        # Simple complexity metrics\n",
    "        if len(lines) < 10:\n",
    "            return 'low'\n",
    "        elif len(lines) < 50:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'high'\n",
    "    \n",
    "    def _get_suggested_libraries(self, vulnerability_type: str, language: str) -> List[str]:\n",
    "        \"\"\"Get suggested security libraries for the fix\"\"\"\n",
    "        suggestions = {\n",
    "            'javascript': {\n",
    "                'SQL Injection': ['mysql2', 'pg', 'knex', 'sequelize'],\n",
    "                'Cross-Site Scripting': ['DOMPurify', 'xss', 'sanitize-html'],\n",
    "                'Path Traversal': ['path', 'fs-extra'],\n",
    "                'Command Injection': ['child_process.execFile', 'shelljs'],\n",
    "                'Insecure Deserialization': ['ajv', 'joi']\n",
    "            },\n",
    "            'python': {\n",
    "                'SQL Injection': ['psycopg2', 'SQLAlchemy', 'Django ORM'],\n",
    "                'Cross-Site Scripting': ['bleach', 'MarkupSafe', 'html.escape'],\n",
    "                'Path Traversal': ['pathlib', 'os.path'],\n",
    "                'Command Injection': ['subprocess with shell=False', 'shlex'],\n",
    "                'Insecure Deserialization': ['json', 'pickle with hmac']\n",
    "            },\n",
    "            'java': {\n",
    "                'SQL Injection': ['PreparedStatement', 'JPA', 'Hibernate'],\n",
    "                'Cross-Site Scripting': ['OWASP Java Encoder', 'StringEscapeUtils'],\n",
    "                'Path Traversal': ['java.nio.file.Path', 'FilenameUtils'],\n",
    "                'Command Injection': ['ProcessBuilder', 'Runtime.exec with array']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        lang_suggestions = suggestions.get(language, {})\n",
    "        vuln_suggestions = lang_suggestions.get(vulnerability_type, [])\n",
    "        \n",
    "        return vuln_suggestions\n",
    "    \n",
    "    def _format_analysis_trace(self, trace: List[str]) -> str:\n",
    "        \"\"\"Format analysis trace with context\"\"\"\n",
    "        if not trace:\n",
    "            return \"No analysis trace available\"\n",
    "        \n",
    "        formatted = []\n",
    "        for i, step in enumerate(trace, 1):\n",
    "            # Add context to each step\n",
    "            if \"Read\" in step:\n",
    "                formatted.append(f\"{i}. 🔍 Data Source: {step}\")\n",
    "            elif \"Assignment\" in step:\n",
    "                formatted.append(f\"{i}. ⚠️  Sink Point: {step}\")\n",
    "            else:\n",
    "                formatted.append(f\"{i}. → Flow: {step}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def _detect_language(self, file_path: str) -> str:\n",
    "        \"\"\"Enhanced language detection\"\"\"\n",
    "        # Handle special cases\n",
    "        if '-jsx' in file_path or '.jsx' in file_path:\n",
    "            return 'javascript'\n",
    "        if '-tsx' in file_path or '.tsx' in file_path:\n",
    "            return 'typescript'\n",
    "        \n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        language_map = {\n",
    "            '.py': 'python',\n",
    "            '.js': 'javascript',\n",
    "            '.jsx': 'javascript',\n",
    "            '.ts': 'typescript',\n",
    "            '.tsx': 'typescript',\n",
    "            '.java': 'java',\n",
    "            '.cs': 'csharp',\n",
    "            '.cpp': 'cpp',\n",
    "            '.c': 'c',\n",
    "            '.rb': 'ruby',\n",
    "            '.go': 'go',\n",
    "            '.php': 'php',\n",
    "            '.rs': 'rust',\n",
    "            '.swift': 'swift',\n",
    "            '.kt': 'kotlin',\n",
    "            '.scala': 'scala',\n",
    "            '.r': 'r',\n",
    "            '.m': 'objective-c'\n",
    "        }\n",
    "        \n",
    "        return language_map.get(ext, 'unknown')\n",
    "    \n",
    "    def create_chain_of_thought_prompt(self, vulnerability: Dict, code_context: str) -> str:\n",
    "        \"\"\"Create a chain-of-thought prompt for complex vulnerabilities\"\"\"\n",
    "        vuln_data = self._normalize_vulnerability_data(vulnerability)\n",
    "        \n",
    "        cot_template = \"\"\"Let's fix this {vulnerability_type} vulnerability step by step.\n",
    "\n",
    "## Step 1: Understand the Vulnerability\n",
    "The vulnerability is at line {line_number} in {file_path}.\n",
    "Fortify says: {recommendation}\n",
    "\n",
    "## Step 2: Analyze the Data Flow\n",
    "{analysis_trace}\n",
    "\n",
    "## Step 3: Identify the Root Cause\n",
    "Looking at the code:\n",
    "```{language}\n",
    "{code_context}\n",
    "```\n",
    "\n",
    "What makes this code vulnerable?\n",
    "\n",
    "## Step 4: Design the Fix\n",
    "Based on {language} best practices for {vulnerability_type}, we should:\n",
    "1. First, identify what user input needs validation\n",
    "2. Then, determine the appropriate security control\n",
    "3. Finally, implement the fix maintaining functionality\n",
    "\n",
    "## Step 5: Implement the Fix\n",
    "Provide the complete fixed code with:\n",
    "- Input validation\n",
    "- Secure coding patterns\n",
    "- Error handling\n",
    "- Comments explaining the security measures\n",
    "\n",
    "## Step 6: Verify the Fix\n",
    "Explain how to test that:\n",
    "1. The vulnerability is fixed\n",
    "2. The functionality still works\n",
    "3. No new vulnerabilities are introduced\"\"\"\n",
    "        \n",
    "        return cot_template.format(**vuln_data, code_context=code_context)\n",
    "    \n",
    "    def save_enhanced_prompt(self, json_file_path: str, issue_id: int, \n",
    "                           code_context: str = None, use_cot: bool = False):\n",
    "        \"\"\"Save enhanced prompt using LangChain\"\"\"\n",
    "        # Load vulnerability data\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            vul_data = json.load(f)\n",
    "        \n",
    "        # Find specific vulnerability\n",
    "        vulnerability = None\n",
    "        for vuln in vul_data.get('table', []):\n",
    "            vuln_id = vuln.get('issueId') or vuln.get('issueld')\n",
    "            if vuln_id == issue_id:\n",
    "                vulnerability = vuln\n",
    "                break\n",
    "        \n",
    "        if not vulnerability:\n",
    "            raise ValueError(f\"Issue ID {issue_id} not found\")\n",
    "        \n",
    "        # Generate enhanced prompt\n",
    "        if use_cot:\n",
    "            prompt = self.create_chain_of_thought_prompt(vulnerability, code_context or '')\n",
    "        else:\n",
    "            prompt = self.generate_prompt_with_context_enhancement(vulnerability, code_context or '')\n",
    "        \n",
    "        # Save to file\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        content = f\"\"\"# ENHANCED FORTIFY PROMPT (LangChain)\n",
    "# Generated: {timestamp}\n",
    "# Issue ID: {issue_id}\n",
    "# Enhancement: {'Chain-of-Thought' if use_cot else 'Context-Enhanced'}\n",
    "\n",
    "{prompt}\n",
    "\n",
    "---\n",
    "Generated with LangChain enhancements\n",
    "\"\"\"\n",
    "        \n",
    "        with open('initialprompt.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(f\"✓ Enhanced prompt saved to initialprompt.txt\")\n",
    "        print(f\"  Using: {'Chain-of-Thought' if use_cot else 'Context Enhancement'}\")\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize enhanced generator\n",
    "    generator = LangChainFortifyPromptGenerator()\n",
    "    \n",
    "    # Example vulnerability from vul.json\n",
    "    example_vulnerability = {\n",
    "        \"issueld\": 27281196,\n",
    "        \"issueName\": \"Cross-Site Scripting: DOM\",\n",
    "        \"filePath\": \"src/components/organisms/CollectionsApp/CollectionsApp-jsx\",\n",
    "        \"lineNumber\": 181,\n",
    "        \"priority\": \"Critical\",\n",
    "        \"recommendation\": \"The solution to prevent XSS is to ensure that validation occurs in the required places and that relevant properties are set to prevent vulnerabilities.\",\n",
    "        \"analysisTrace\": [\n",
    "            \"CollectionsApp.jsx:181 - Read window.location\",\n",
    "            \"CollectionsApp.jsx:181 - Assignment to window.location.href\"\n",
    "        ],\n",
    "        \"status\": \"Reviewed\"\n",
    "    }\n",
    "    \n",
    "    # Example code context\n",
    "    code_context = \"\"\"\n",
    "const CollectionsApp = () => {\n",
    "    const handleRedirect = (url) => {\n",
    "        // Line 181: Vulnerable code\n",
    "        window.location.href = url;  // Direct assignment without validation\n",
    "    };\n",
    "    \n",
    "    return (\n",
    "        <div onClick={() => handleRedirect(userInput)}>\n",
    "            Navigate\n",
    "        </div>\n",
    "    );\n",
    "};\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate enhanced prompt\n",
    "    enhanced_prompt = generator.generate_prompt_with_context_enhancement(\n",
    "        example_vulnerability, \n",
    "        code_context\n",
    "    )\n",
    "    \n",
    "    print(\"Enhanced Prompt Preview:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(enhanced_prompt[:1000] + \"...\")\n",
    "    \n",
    "    # Generate chain-of-thought prompt\n",
    "    print(\"\\n\\nChain-of-Thought Prompt Preview:\")\n",
    "    print(\"=\" * 50)\n",
    "    cot_prompt = generator.create_chain_of_thought_prompt(\n",
    "        example_vulnerability,\n",
    "        code_context\n",
    "    )\n",
    "    print(cot_prompt[:1000] + \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
